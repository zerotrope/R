---
title: "Penalized Cox Regression"
---

Recap
- First
- Strata
- Diagnostics: what to do if hypothesis of proportionality of hazards does not hild? If it doesn't matter you ignore it otherwise
	- Cox stratification
	- truncation: cut the sample to simplify the observations and see if the differences significant or not (if they are due
to hazard or not).

Here, Penalized regression
when lots of features (millions?) compared to sample size. We impose constraints on the beta, bounding it to
do not exceed some threshold c. This is due to the fact that when the number of features p > the number operations n, the beta 
that maximizes the MLE goes +inf. 
 - glmnet(x, y, fmily ="cox")
It allows to identify the "trajectories" of the betas.
Cross validation allows you to identify what threshold level should I settle.

---

# Simulated data

```{r}
library(survival)
library(glmnet)
```

## Data generation
```{r}
set.seed(1234)

N <- 1000
p <- 30  # total num. features
nzc <- p/3 # num. 'true' predictors

X <- matrix(rnorm(N * p), nrow = N, ncol = p)
beta <- rnorm(nzc)
linear_predictor <- X[, seq_len(nzc)] %*% beta
hazard <- exp(linear_predictor)
y_time_event <- rexp(N, rate = hazard)
y_time_censoring <- rexp(N, rate = hazard * 0.5)
y_time <- pmin(y_time_event, y_time_censoring)
y_event <- y_time_event <= y_time_censoring
y <- Surv(y_time, y_event)
```
Matrix multiplication X (n x p matrix) . beta (p x 1 column vector) = predictor (n x 1 column vector)

We should have about 1/3 of the data points censored:
```{r}
table(y_event)
```

## Fit the model
```{r}
fit <- glmnet(X, y, family = "cox")
plot(fit)
```

## Selecting a threshold through cross-validation
```{r}
set.seed(1234)
fit.cv10 <- cv.glmnet(X, y, family = "cox")
plot(fit.cv10)
```

```{r}
str(fit.cv10)
```

Estimated coefficients:
```{r}
coef(fit.cv10, s = "lambda.1se")
```

Compare estimated values with 'true' values:
```{r}
beta.true <- c(round(beta, 2), rep(0, ncol(X) - length(beta)))
beta.est <- round(coef(fit.cv10, s = "lambda.1se"), 2)
cbind(beta.true, beta.est)
```

## Make predictions
Using built-in functions:
```{r}
predict(fit.cv10, newx = X[1:5, ], s = "lambda.1se")
```

'Manually':
```{r}
b <- coef(fit.cv10, s = "lambda.1se")
b.i <- which(b != 0)
bnz <- b[b.i]
y0 <- X[1:5, b.i, drop = FALSE] %*% bnz
print(y0)
```

# Case study nr. 1
Slide 117

## Load data and packages
```{r}
library(survival)
library(glmnet)

load('LymphomaData.rda')

str(patient.data)
```

Create a matrix 'gex' (gene expression) transposing the original to get samples (n) in rows and features (p) in columns
```{r}
gex <- t(patient.data$x)
y <- Surv(patient.data$time, patient.data$status)
```

## Exploratory analysis
See how the survival looks like
```{r}
plot(survfit(y ~ 1))
```
Survival in months probably. Nothing wrong here apparently.

See all the features of the gex altogether, converting rows and columns in a single vector
```{r}
hist(as.vector(gex))
```
Wde don't know gex so we don't have any expectation in particular. Does it look right at least? Looks alright, roughly symetric very accutely skewed, pinched in the middle. Typical from these kind of data apparently says Antonio.

Computing a vector of averages per gene per feature. We get a vector of 7399 averages and make an histogram of it:
```{r}
hist(colMeans(gex))
```
Still very little expectations, usually centered around 0 which seems to be roughly the case here.

Apply to the columns (2) the function sd(), computing the standard deviation for each column, thus getting 7399 and make an histogram of it:
```{r}
hist(apply(gex, 2, sd))
```
SCaling might be a problem for some models which is not the case for Cox penalized regression model.
Not much more we can do with descriptive statistics.

## Split the data randomly into a training and a testing set
```{r}
i.training <- sample.int(nrow(gex), size = 160, replace = FALSE)
i.testing <- setdiff(seq_len(nrow(gex)), i.training)

gex.training <- gex[i.training,, drop = FALSE]
y.training <- y[i.training,, drop = FALSE]

gex.testing <- gex[i.testing,, drop = FALSE]
y.testing <- y[i.testing,, drop = FALSE]
```
i.training extracts 160 random rows from gex without replacement.
i.testing will be comprised by the remainder rows.

## Train the model
```{r}
fit.cv10 <- cv.glmnet(gex.training, y.training, family = "cox")
```

plot the results:
```{r}
plot(fit.cv10)
```

```{r}
b <- coef(fit.cv10, s = "lambda.min")
sum(b != 0)
```

```{r}
round(b[b != 0], digits = 3)
```

## Test the model
```{r}
score.testing <- predict(fit.cv10, newx = gex.testing, s = "lambda.min")
hist(score.testing)
```

Question: how well is the score predicting survival?

A continuous predictor vs a right-censored time-to-failure outcome: Cox regression!
```{r}
summary(coxph(y.testing ~ score.testing))
```
It works! pvalue significant (0.00149) so the score is related to the deaths. Positive beta, the higer the score, the more deaths.

A more interpretable scale: by IQR variation:
```{r}
score_scaled.testing <- score.testing / IQR(score.testing)
summary(coxph(y.testing ~ score_scaled.testing))
```

We can split the scores into 2 categories, and compare patients with 'low' vs 'high' score:
```{r}
gex_risk <- ifelse(score.testing <= median(score.testing), "low", "high")
table(gex_risk)
```

```{r}
fit.KM <- survfit(y.testing ~ gex_risk, conf.type = "log-log")
plot(fit.KM)
```

```{r}
fit.KM
```


Question: how is the 6 months survival for patients classified as low risk, compared to patients classified as high risk?

```{r}
summary(fit.KM, time = 6)
```

```{r}
library(survivalROC)
ROC <- survivalROC(Stime = y.testing[, 1],
                   status = y.testing[, 2],
                   marker = score.testing,
                   cut.values = quantile(score.testing, prob = 0:10/10),
                   predict.time = 10,
                   method = "KM")
ROC$AUC
```

```{r}
with(ROC, plot(TP ~ FP, type = "l", xlim = c(0, 1), ylim = c(0, 1)))
```
